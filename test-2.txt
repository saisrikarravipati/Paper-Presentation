
#!/usr/bin/env python3
import os
import json
import time
import uuid
import copy
import boto3
from datetime import datetime

# Determine script and templates directory
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATES_DIR = os.path.join(SCRIPT_DIR, "templates")


def replace_placeholders(obj):
    """
    Recursively replace any string == "PLACEHOLDER" with a unique value:
    - For keys containing 'timestamp', use ISO8601 UTC timestamp
    - Otherwise, use a UUID
    """
    if isinstance(obj, dict):
        new = {}
        for k, v in obj.items():
            if v == "PLACEHOLDER":
                key_lc = k.lower()
                if "timestamp" in key_lc:
                    new[k] = datetime.utcnow().isoformat() + "Z"
                else:
                    new[k] = str(uuid.uuid4())
            else:
                new[k] = replace_placeholders(v)
        return new
    elif isinstance(obj, list):
        return [replace_placeholders(item) for item in obj]
    else:
        return obj


def generate_mock_messages(template_data, count):
    """
    Generate a list of 'count' messages from template_data.
    template_data can be a dict or a list of dicts.
    """
    if isinstance(template_data, list):
        templates = template_data
    else:
        templates = [template_data]

    msgs = []
    for i in range(count):
        base = templates[i % len(templates)]
        # Deep copy base template to avoid mutation
        msg = replace_placeholders(copy.deepcopy(base))
        msgs.append(msg)
    return msgs


def write_messages_to_file(msgs, filename):
    """
    Write the list of messages to a JSON file.
    """
    with open(filename, "w") as f:
        json.dump(msgs, f, indent=2)
    print(f"→ Wrote {len(msgs)} messages to {filename}")


def send_messages(sqs, queue_url, msgs, batch_size=10, rate=0.0):
    """
    Send messages to SQS in batches.
    - rate: target messages per second (0 = no throttle)
    """
    send_times = []
    total = len(msgs)
    for i in range(0, total, batch_size):
        batch = msgs[i : i + batch_size]
        entries = [
            {"Id": str(idx), "MessageBody": json.dumps(body)}
            for idx, body in enumerate(batch)
        ]
        t0 = time.monotonic()
        resp = sqs.send_message_batch(QueueUrl=queue_url, Entries=entries)
        t1 = time.monotonic()

        # compute average send time per message in ms
        send_times.append((t1 - t0) * 1000 / len(entries))

        if resp.get("Failed"):
            print(f"!! Failed entries for batch {i//batch_size}: {resp['Failed']}")

        if rate > 0:
            desired = len(entries) / rate
            actual = time.monotonic() - t1
            if desired > actual:
                time.sleep(desired - actual)

    avg = sum(send_times) / len(send_times) if send_times else 0
    print(f"→ Sent {total} msgs to {queue_url} in {len(send_times)} batches; avg send-latency {avg:.2f} ms/msg\n")


def main():
    # Load AWS region and queue config
    region = os.getenv("AWS_REGION", "us-west-2")
    config_path = os.path.join(TEMPLATES_DIR, "queue_config.json")

    # Load queue configuration
    with open(config_path) as cf:
        config = json.load(cf)

    # Pre-generate all messages
    all_messages = {}
    for q in config["queues"]:
        name = q["name"]
        tmpl_file = os.path.join(TEMPLATES_DIR, q["template_file"])
        count = q["message_count"]
        rate = q.get("message_rate", 0.0)

        # Load template data (dict or list)
        with open(tmpl_file) as tf:
            template_data = json.load(tf)

        msgs = generate_mock_messages(template_data, count)
        sample_file = f"sample_messages_{name}.json"
        write_messages_to_file(msgs, sample_file)

        all_messages[name] = {
            "queue_url": q["queue_url"],
            "messages": msgs,
            "message_rate": rate
        }

    # Initialize SQS client
    sqs = boto3.client("sqs", region_name=region)

    # Publish messages
    for name, info in all_messages.items():
        print(f"=== Publishing to queue '{name}' ===")
        send_messages(
            sqs,
            info["queue_url"],
            info["messages"],
            batch_size=10,
            rate=info["message_rate"]
        )

if __name__ == "__main__":
    main()
