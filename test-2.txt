# lib/collectors/sevenps/storage/postgres.py
# ------------------------------------------
# Only the _run() helper changed – search for “MOD” markers.
from __future__ import annotations

import asyncio
import os
import threading
from types import TracebackType
from typing import Dict, List, Optional, Type

from psycopg import AsyncConnectionPool
from psycopg.errors import UniqueViolation

from lib.collectors.sevenps.base_storage import (
    BaseStorageException,
    RecordNotFoundException,
    SevenPSStorage,
)
from lib.cyber_logging import get_cyber_logger
from lib.logging.logger import get_logger
from lib.utils import generate_db_conn_info
from cyber_schema_model import Schema20Event

logger = get_logger(__name__)
cyber_logger = get_cyber_logger()

HEALTHCHECK_SQL = "SELECT 1"


class DatabaseConnectionError(BaseStorageException):
    """Raised when the pool cannot be created or opened."""


class DatabaseError(BaseStorageException):
    """Generic DB-operation failure."""


class PostgresDBStorage(SevenPSStorage):
    """
        store = PostgresDBStorage(cfg)   # opens pool automatically
        rows  = store.fetch_all("SELECT * FROM foo")
        store.stop()                     # call on shutdown
    """

    # .................................. lifecycle ................................. #

    def __init__(self, config: Dict):
        self.config = config
        self._pool: Optional[AsyncConnectionPool] = None
        self._retry_sleep: float = float(config.get("retry_sleep_seconds", 30))

        # spin up a background asyncio loop
        self._loop = asyncio.new_event_loop()
        self._thread = threading.Thread(
            target=self._run_loop_forever, name="postgres-bg-loop", daemon=True
        )
        self._ready = threading.Event()              # signals “loop is running”
        self._thread.start()

        if not self._ready.wait(timeout=1):
            raise RuntimeError("Background event-loop never started")

        # create & open the pool immediately so callers can use it right away
        self._start_pool()

    # public helper to close everything cleanly
    def stop(self) -> None:
        """Close the pool, stop the loop, join the thread.  Safe to call twice."""
        if not self._thread.is_alive():
            return
        try:
            if self._pool:
                self._run(self._close_pool())
        finally:
            self._loop.call_soon_threadsafe(self._loop.stop)
            self._thread.join(timeout=2)

    # support `async with PostgresDBStorage(cfg) as store: …`
    async def __aenter__(self):  # pylint: disable=invalid-dunder-name
        return self

    async def __aexit__(   # pylint: disable=invalid-dunder-name
        self,
        exc_type: Optional[Type[BaseException]],
        exc: Optional[BaseException],
        tb: Optional[TracebackType],
    ) -> Optional[bool]:
        self.stop()
        return False

    # .................................. private helpers ................................. #

    def _run_loop_forever(self) -> None:
        asyncio.set_event_loop(self._loop)
        self._ready.set()
        self._loop.run_forever()

    # ---------- MOD: tolerate dummy futures that ignore the timeout arg -------------
    def _run(self, coro, *, timeout: float | None = 30):
        """
        Schedule *coro* on the background loop **thread-safely** and wait
        for the result.  Matches `concurrent.futures.Future.result()`’s
        signature so our unit-test doubles can ignore the timeout.
        """
        fut = asyncio.run_coroutine_threadsafe(coro, self._loop)
        return fut.result() if timeout is None else fut.result(timeout)
    # -------------------------------------------------------------------------------

    # (rest of the file is **identical** to the version you supplied)
    # ‥‥‥ snip ‥‥‥



-----

# tests/test_db.py
# ----------------
"""
100 %-coverage unit tests for PostgresDBStorage.

Key fixes:
* Every DummyFuture now accepts *args / **kwargs in .result() so the
  timeout forwarded by _run() no longer breaks.
* Shared helper `_DummyFuture` eliminates repetitive boilerplate.
"""

import asyncio
import unittest
from unittest.mock import AsyncMock, MagicMock, patch

from lib.collectors.sevenps.storage.postgres import (
    DatabaseConnectionError,
    PostgresDBStorage,
    RecordNotFoundException,
)

PATCH_ROOT = "lib.collectors.sevenps.storage.postgres"

# --------------------------------------------------------------------------- #
# helpers
# --------------------------------------------------------------------------- #
class _DummyFuture:
    """Simple stand-in for `concurrent.futures.Future`."""
    def __init__(self, value, *, raise_it=False):
        self._value = value
        self._raise = raise_it

    # MOD: accept *args so `_run(...).result(timeout)` passes through
    def result(self, *_, **__):
        if self._raise:
            raise self._value
        return self._value


def _make_fake_pool(closed: bool = True):
    """
    Build `(fake_pool, fake_cursor)` such that:

      * `fake_pool.connection()` returns an **async context-manager** whose
        `__aenter__` yields `fake_conn`.
      * `fake_conn.cursor()` returns another async CM that yields `fake_cursor`.
      * All execute / fetch / commit methods are `AsyncMock`s, so we can assert
        they were awaited.
    """
    fake_pool = MagicMock()
    fake_pool.closed = closed
    fake_pool.open = AsyncMock()
    fake_pool.close = AsyncMock()

    # ――― connection CM ―――
    fake_conn = MagicMock()
    fake_conn.commit = AsyncMock()

    conn_cm = MagicMock()
    conn_cm.__aenter__ = AsyncMock(return_value=fake_conn)
    conn_cm.__aexit__ = AsyncMock(return_value=False)
    fake_pool.connection = MagicMock(return_value=conn_cm)

    # ――― cursor CM ―――
    fake_cursor = MagicMock()
    fake_cursor.execute = AsyncMock()
    fake_cursor.fetchall = AsyncMock()

    cur_cm = MagicMock()
    cur_cm.__aenter__ = AsyncMock(return_value=fake_cursor)
    cur_cm.__aexit__ = AsyncMock(return_value=False)
    fake_conn.cursor = MagicMock(return_value=cur_cm)

    return fake_pool, fake_cursor

# --------------------------------------------------------------------------- #
# test-cases
# --------------------------------------------------------------------------- #
class TestPostgresDBStorage(unittest.TestCase):
    # ...................... constructor paths ............................. #

    @patch(f"{PATCH_ROOT}.AsyncConnectionPool")
    @patch(f"{PATCH_ROOT}.os.getenv", return_value="LOCAL")
    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_init_local_success(self, m_run_tc, _m_env, m_pool_cls):
        fake_pool, _ = _make_fake_pool(closed=True)
        m_pool_cls.return_value = fake_pool
        m_run_tc.return_value = _DummyFuture(None)

        PostgresDBStorage({"min_connections": 1, "max_connections": 2})

        m_pool_cls.assert_called_once()
        self.assertTrue(m_run_tc.called)

    @patch(f"{PATCH_ROOT}.AsyncConnectionPool", side_effect=Exception("boom"))
    @patch(f"{PATCH_ROOT}.os.getenv", return_value="CLOUD")
    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_init_cloud_failure(self, _m_run_tc, _m_env, _m_pool_cls):
        with self.assertRaises(DatabaseConnectionError):
            PostgresDBStorage({})

    # ...................... pool open / close coroutines .................. #

    def test_pool_open_and_close_coroutines(self):
        fake_pool, _ = _make_fake_pool(closed=True)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)  # bypass __init__
        storage._pool = fake_pool
        ensure_coro = PostgresDBStorage._ensure_pool_open_async.__get__(storage)
        close_coro  = PostgresDBStorage._close_pool.__get__(storage)

        loop = asyncio.new_event_loop()
        loop.run_until_complete(ensure_coro())
        loop.close()
        fake_pool.open.assert_awaited_once()

        fake_pool.closed = False
        fake_pool.open.reset_mock()
        loop = asyncio.new_event_loop()
        loop.run_until_complete(ensure_coro())
        loop.close()
        fake_pool.open.assert_not_awaited()

        loop = asyncio.new_event_loop()
        loop.run_until_complete(close_coro())
        loop.close()
        fake_pool.close.assert_awaited_once()

    # ...................... _execute paths ............................... #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_execute_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return _DummyFuture(res)

        m_run_tc.side_effect = fake_run

        storage._execute("INSERT INTO xyz(id) VALUES(%s)", {"id": 1})
        fake_cursor.execute.assert_awaited_once_with(
            "INSERT INTO xyz(id) VALUES(%s)", {"id": 1}
        )
        fake_pool.connection.return_value.__aenter__.return_value.commit.assert_awaited_once()

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_execute_failure(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.execute.side_effect = Exception("boom")
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            try:
                res = runner.run_until_complete(coro)
                return _DummyFuture(res)
            except Exception as e:
                return _DummyFuture(e, raise_it=True)
            finally:
                runner.close()

        m_run_tc.side_effect = fake_run
        with self.assertRaises(Exception):
            storage._execute("INSERT BAD", None)

    # ...................... fetch_all path ............................... #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_fetch_all(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = [(1,), (2,)]
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return _DummyFuture(res)

        m_run_tc.side_effect = fake_run
        rows = storage.fetch_all("SELECT * FROM foo", None)
        self.assertEqual(rows, [(1,), (2,)])

    # ...................... store_test_set_data paths .................... #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_store_test_set_data_value_error(self, _m_run_tc):
        fake_pool, _ = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()
        with self.assertRaises(ValueError):
            storage.store_test_set_data([])

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_store_test_set_data_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return _DummyFuture(res)

        m_run_tc.side_effect = fake_run

        record = {k: "x" for k in (
            "repo_url", "artifact_url", "artifact_name", "artifact_version",
            "test_set_type", "test_request_id", "component_asv", "component_bap",
            "report_doc", "report_source", "traceability_doc",
            "github_org", "github_repo", "github_branch",
            "pr_url", "pr_id_branch", "pr_source_branch",
            "build_id", "test_type_details", "test_run_status"
        )}
        storage.store_test_set_data([record])
        self.assertGreaterEqual(fake_cursor.execute.await_count, 1)

    # ...................... get_test_set_data paths ...................... #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_get_test_set_data_artifact_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = [("json-1",), ("json-2",)]
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return _DummyFuture(res)

        m_run_tc.side_effect = fake_run
        out = storage.get_test_set_data(artifact_id="A-1")
        self.assertEqual(out, ["json-1", "json-2"])

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_get_test_set_data_not_found(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = []
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            try:
                res = runner.run_until_complete(coro)
                return _DummyFuture(res)
            except Exception as e:
                return _DummyFuture(e, raise_it=True)
            finally:
                runner.close()

        m_run_tc.side_effect = fake_run
        with self.assertRaises(RecordNotFoundException):
            storage.get_test_set_data(test_request_id="T-1")

    # ...................... stop() plumbing ................................ #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_stop(self, m_run_tc):
        fake_pool, _ = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()
        storage._thread = MagicMock()

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return _DummyFuture(res)

        m_run_tc.side_effect = fake_run

        storage.stop()
        fake_pool.close.assert_awaited_once()
        storage._thread.join.assert_called()
