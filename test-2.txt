
"""
postgres.py
Synchronous psycopg-pool implementation for SevenPS storage.

Key fixes vs. original
──────────────────────
* 100 % resource-safe: every connection and cursor is now managed with
  `with` blocks so leaks cannot starve the pool.
* In-flight transactions are *always* rolled back on error before the
  connection returns to the pool.
* Commit happens once per batch and only on the happy path.
* `get_test_set_data` is strictly read-only (no commit).
* Added `close()` to drain and shut down the pool gracefully.
"""

from __future__ import annotations

import os
import time
from typing import Dict, List

import psycopg
from psycopg.errors import UniqueViolation, Error as PsycopgError
from psycopg_pool import ConnectionPool  # ← correct import path

from lib.collectors.sevenps.base_storage import (
    BaseStorageException,
    RecordNotFoundException,
    SevenPSStorage,
)
from lib.cyber_logging import get_cyber_logger
from lib.logging.logger import get_logger
from cyber_schema_model import Schema20Event

logger = get_logger(__name__)
cyber_logger = get_cyber_logger()


# ─────────────────────────── custom error types ────────────────────────── #
class DatabaseConnectionError(BaseStorageException):
    """Raised when the pool cannot be created."""


class DatabaseError(BaseStorageException):
    """Raised for generic write/read failures."""


# ───────────────────────────── main storage ────────────────────────────── #
class PostgresDBStorage(SevenPSStorage):
    """Blocking variant that uses psycopg-pool.ConnectionPool."""

    # ------------------------------------------------------------------ #
    # construction / teardown
    # ------------------------------------------------------------------ #
    def __init__(self, config: Dict):
        self.config = config
        conn_info = self._get_conn_info()

        try:
            # The pool itself is lightweight; open=True pre-creates min_size conns.
            self.conn_pool = ConnectionPool(
                conn_info,
                min_size=self.config.get("min_connections", 1),
                max_size=self.config.get("max_connections", 3),
                open=True,
            )
            logger.info("Connected to DB – %s", self.conn_pool.conninfo)
        except Exception as exc:  # pragma: no cover  – catastrophic
            event = Schema20Event(
                event_name="Unable to connect to DB",
                event_severity="ERROR",
                event_outcome="FAILURE",
            )
            cyber_logger.log(event)
            raise DatabaseConnectionError(
                "SEVENPS-COLLECTOR-ERROR: Unable to construct ConnectionPool"
            ) from exc

    def close(self) -> None:
        """
        Graceful shutdown.

        *Drains* and terminates every idle connection instead of just returning
        one borrowed connection. Safe to call multiple times.
        """
        try:
            self.conn_pool.close()
            self.conn_pool.join()  # wait until all conns are closed
            logger.info("ConnectionPool closed cleanly")
        except Exception as exc:
            logger.warning("Failed to close ConnectionPool cleanly: %s", exc)

    # ------------------------------------------------------------------ #
    # internal helpers
    # ------------------------------------------------------------------ #
    def _get_conn_info(self) -> str:
        """
        Build a libpq conninfo string from env-vars.

        We keep it simple here – real code could delegate to a central helper.
        """
        if os.getenv("CLOUD", "false").lower() == "true":
            return (
                f"user={os.getenv('DB_APP_USERNAME')} "
                f"password={os.getenv('DB_APP_PASSWORD')} "
                f"host={os.getenv('DB_HOST')} "
                f"port=5432 dbname={os.getenv('DATABASE')}"
            )
        # Local developer default
        logger.info("Using local DB credentials")
        return (
            "user=insights_app "
            "password=CHANGE_ME "
            "host=testing-insights-db-batestinginsightsplatform-dev.clouddqt.capitalone.com "
            "port=5432 dbname=testinginsightsdb"
        )

    # ------------------------------------------------------------------ #
    # write API
    # ------------------------------------------------------------------ #
    def store_test_set_data_async(self, records: List[Dict]) -> None:
        """
        Batch-insert records into sevenps_result_set.

        - Retries transient errors up to six times.
        - UniqueViolation is not retried – it’s a data problem, not infra.
        """
        if not records:
            logger.info("SEVENPS-COLLECTOR-ERROR: No records to store")
            raise ValueError("No records to store")

        tries_remaining = 6

        while True:
            try:
                # Acquire a connection from the pool – the context manager
                # auto-returns it, even on exception.
                with self.conn_pool.connection() as conn:
                    with conn.cursor() as cur:
                        for rec in records:
                            logger.info(
                                "Inserting record – Artifact: %s:%s",
                                rec.get("artifact_url"),
                                rec.get("artifact_version"),
                            )
                            cur.execute(
                                """
                                INSERT INTO sevenps_result_set
                                  (repo_url, artifact_url, artifact_name, artifact_version,
                                   test_set_type, test_request_id, component_asv, component_bap,
                                   report_doc, report_source, traceability_doc,
                                   github_org, github_repo, github_branch,
                                   pr_url, pr_id_branch, pr_source_branch,
                                   build_id, test_type_details, test_run_status)
                                VALUES
                                  (%(repo_url)s, %(artifact_url)s, %(artifact_name)s, %(artifact_version)s,
                                   %(test_set_type)s, %(test_request_id)s, %(component_asv)s, %(component_bap)s,
                                   %(report_doc)s, %(report_source)s, %(traceability_doc)s,
                                   %(github_org)s, %(github_repo)s, %(github_branch)s,
                                   %(pr_url)s, %(pr_id_branch)s, %(pr_source_branch)s,
                                   %(build_id)s, %(test_type_details)s, %(test_run_status)s)
                                """,
                                rec,
                            )

                        # Commit once per batch – *inside* the with-block so
                        # rollback is still possible if commit itself fails.
                        conn.commit()
                        logger.info(
                            "Successfully wrote %d records to sevenps_result_set",
                            len(records),
                        )
                # Success — break out of retry loop
                return

            except UniqueViolation as uv:
                logger.error(
                    "SEVENPS-COLLECTOR-ERROR: Duplicate record (UniqueViolation): %s",
                    uv,
                )
                raise  # caller decides what to do with duplicates

            except Exception as exc:
                tries_remaining -= 1
                logger.error(
                    "SEVENPS-COLLECTOR-ERROR: Write failed, tries left=%d – %s",
                    tries_remaining,
                    exc,
                )

                # Attempt rollback *before* the connection context closes.
                # If the conn is already aborted, rollback() is a no-op.
                try:
                    conn.rollback()  # type: ignore[name-defined]
                except Exception:  # pragma: no cover
                    pass

                if tries_remaining < 0:
                    event = Schema20Event(
                        event_name="Unable to write to DB",
                        event_severity="ERROR",
                        event_outcome="FAILURE",
                    )
                    cyber_logger.log(event)
                    raise DatabaseError(
                        "SEVENPS-COLLECTOR-ERROR: Unable to write record to DB"
                    ) from exc

                time.sleep(30)  # basic back-off; patch to no-op in tests

    # ------------------------------------------------------------------ #
    # read API
    # ------------------------------------------------------------------ #
    def get_test_set_data(
        self, *, test_request_id: str | None = None, artifact_id: str | None = None
    ) -> List[str]:
        """
        Fetch `results` column by either `artifact_id` *or* `test_request_id`.

        Read-only → no commit() call.
        """
        if not (artifact_id or test_request_id):
            raise ValueError("Either artifact_id or test_request_id must be provided")

        with self.conn_pool.connection() as conn:
            with conn.cursor() as cur:
                if artifact_id:
                    cur.execute(
                        """
                        SELECT results
                        FROM sevenps_result_set
                        WHERE artifact_id = %s
                        """,
                        (artifact_id,),
                    )
                else:
                    cur.execute(
                        """
                        SELECT results
                        FROM sevenps_result_set
                        WHERE test_request_id = %s
                        """,
                        (test_request_id,),
                    )

                rows = cur.fetchall()

        if not rows:
            event = Schema20Event(
                event_name="No test results found",
                event_severity="ERROR",
                event_outcome="NOT_FOUND",
            )
            cyber_logger.log(event)
            raise RecordNotFoundException(
                "SEVENPS-COLLECTOR-ERROR: No test results found with the provided ID"
            )

        # rows is a list of 1-tuples like [('{"json": 1}',)]
        return [r[0] for r in rows]

    # ------------------------------------------------------------------ #
    # legacy hook – kept for compatibility
    # ------------------------------------------------------------------ #
    def stopped(self) -> None:  # noqa: D401
        """Legacy shutdown shim – delegates to the new `close()`."""
        self.close()
