from __future__ import annotations

import asyncio
import os
import threading
from typing import Dict, List, Optional

from psycopg import AsyncConnectionPool
from psycopg.errors import UniqueViolation

from lib.collectors.sevenps.base_storage import (
    BaseStorageException,
    RecordNotFoundException,
    SevenPSStorage,
)
from lib.cyber_logging import get_cyber_logger
from lib.logging.logger import get_logger
from lib.utils import generate_db_conn_info
from cyber_schema_model import Schema20Event  # adjust if your project layout differs

logger = get_logger(__name__)
cyber_logger = get_cyber_logger()


class DatabaseConnectionError(BaseStorageException):
    """Cannot connect to DB"""


class DatabaseError(BaseStorageException):
    """General DB error"""


class PostgresDBStorage(SevenPSStorage):
    """
    Synchronous public API backed by a background asyncio loop + AsyncConnectionPool.
    """

    # ─────────────────────────── constructor / teardown ────────────────────────── #

    def __init__(self, config: Dict):
        self.config = config
        self._pool: Optional[AsyncConnectionPool] = None

        conninfo = (
            generate_db_conn_info()
            if os.getenv("CLOUD", "LOCAL").upper() == "CLOUD"
            else "host=localhost port=5432 dbname=testinginsightsdb user=user password=password"
        )

        # background event-loop in dedicated thread
        self._loop = asyncio.new_event_loop()
        self._thread = threading.Thread(
            target=self._run_loop_forever, daemon=True, name="postgres-bg-loop"
        )
        self._thread.start()

        try:
            self._pool = AsyncConnectionPool(
                conninfo=conninfo,
                min_size=config.get("min_connections", 1),
                max_size=config.get("max_connections", 5),
                timeout=180,
            )
        except Exception as exc:
            cyber_logger.log(
                Schema20Event(
                    event_name="Unable to construct AsyncConnectionPool", event_severity="ERROR"
                )
            )
            raise DatabaseConnectionError(
                "SEVENPS-COLLECTOR-ERROR: Unable to construct AsyncConnectionPool"
            ) from exc

        # open the pool on that loop – block until done
        try:
            asyncio.run_coroutine_threadsafe(self._pool.open(), self._loop).result()
        except Exception as exc:
            cyber_logger.log(
                Schema20Event(
                    event_name="Unable to open AsyncConnectionPool", event_severity="ERROR"
                )
            )
            raise DatabaseConnectionError(
                "SEVENPS-COLLECTOR-ERROR: Unable to open AsyncConnectionPool"
            ) from exc

    def _run_loop_forever(self) -> None:
        asyncio.set_event_loop(self._loop)
        self._loop.run_forever()

    def __del__(self):
        try:
            self.close()
        except Exception:
            pass

    def close(self) -> None:
        """Close pool, stop loop, join thread – all synchronously."""
        if hasattr(self, "_loop") and self._pool:
            asyncio.run_coroutine_threadsafe(self._close_pool(), self._loop).result()
            if self._loop.is_running():
                self._loop.call_soon_threadsafe(self._loop.stop)
            self._thread.join(timeout=2)

    async def _close_pool(self) -> None:
        if self._pool and not self._pool.closed:
            await self._pool.close()

    async def _ensure_pool_open_async(self) -> None:
        if self._pool is None:
            raise DatabaseConnectionError("Connection-pool never initialised")
        if self._pool.closed:
            await self._pool.open()

    # ─────────────────────────── low-level helpers ────────────────────────────── #

    def _run(self, coro):
        """Utility: schedule *coro* on background loop and wait for result/raise."""
        return asyncio.run_coroutine_threadsafe(coro, self._loop).result()

    # ───────────────────────────── query helpers ─────────────────────────────── #

    def _execute(self, query: str, params: Optional[Dict] = None) -> None:
        self._run(self._execute_async(query, params))

    async def _execute_async(self, query: str, params: Optional[Dict] = None) -> None:
        await self._ensure_pool_open_async()
        async with self._pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute(query, params)
                await conn.commit()

    def fetch_all(self, query: str, params: Optional[Dict] = None):
        return self._run(self.fetch_all_async(query, params))

    async def fetch_all_async(self, query: str, params: Optional[Dict] = None):
        await self._ensure_pool_open_async()
        async with self._pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute(query, params)
                return await cur.fetchall()

    # ───────────────────────── seven-ps specific API ─────────────────────────── #

    def store_test_set_data(self, records: List[Dict]) -> None:
        if not records:
            raise ValueError("SEVENPS-COLLECTOR-ERROR: No records to store")
        self._run(self.store_test_set_data_async(records))

    async def store_test_set_data_async(self, records: List[Dict]) -> None:
        await self._ensure_pool_open_async()
        tries = 6
        while tries >= 0:
            try:
                async with self._pool.connection() as conn, conn.cursor() as cur:
                    for rec in records:
                        await cur.execute(
                            """
                            INSERT INTO sevenps_result_set
                              (repo_url, artifact_url, artifact_name, artifact_version,
                               test_set_type, test_request_id, component_asv, component_bap,
                               report_doc, report_source, traceability_doc,
                               github_org, github_repo, github_branch,
                               pr_url, pr_id_branch, pr_source_branch,
                               build_id, test_type_details, test_run_status)
                            VALUES
                              (%(repo_url)s, %(artifact_url)s, %(artifact_name)s, %(artifact_version)s,
                               %(test_set_type)s, %(test_request_id)s, %(component_asv)s, %(component_bap)s,
                               %(report_doc)s, %(report_source)s, %(traceability_doc)s,
                               %(github_org)s, %(github_repo)s, %(github_branch)s,
                               %(pr_url)s, %(pr_id_branch)s, %(pr_source_branch)s,
                               %(build_id)s, %(test_type_details)s, %(test_run_status)s)
                            """,
                            rec,
                        )
                    await conn.commit()
                    return
            except UniqueViolation:
                logger.exception("Unique-violation inserting record")
                raise
            except Exception as exc:
                tries -= 1
                if tries < 0:
                    cyber_logger.log(
                        Schema20Event(
                            event_name="Unable to write to DB",
                            event_severity="ERROR",
                            event_outcome="FAILURE",
                        )
                    )
                    raise DatabaseError(
                        "SEVENPS-COLLECTOR-ERROR: Unable to write record to db"
                    ) from exc
                await asyncio.sleep(0)  # tiny yield in tests, real code could be 30 s

    # ------------------------------------------------------------------------- #

    def get_test_set_data(
        self, *, test_request_id: Optional[str] = None, artifact_id: Optional[str] = None
    ):
        return self._run(
            self.get_test_set_data_async(
                test_request_id=test_request_id, artifact_id=artifact_id
            )
        )

    async def get_test_set_data_async(
        self, *, test_request_id: Optional[str] = None, artifact_id: Optional[str] = None
    ):
        if artifact_id:
            sql, params = "SELECT results FROM sevenps_result_set WHERE artifact_id = $1", (
                artifact_id,
            )
        elif test_request_id:
            sql, params = (
                "SELECT results FROM sevenps_result_set WHERE test_request_id = $1",
                (test_request_id,),
            )
        else:
            raise ValueError("artifact_id or test_request_id is required")

        await self._ensure_pool_open_async()
        async with self._pool.connection() as conn, conn.cursor() as cur:
            await cur.execute(sql, params)
            rows = await cur.fetchall()

        if not rows:
            raise RecordNotFoundException(
                "SEVENPS-COLLECTOR-ERROR: No test results found with the provided ID"
            )
        return [r[0] for r in rows]



------------


import asyncio
import unittest
from unittest.mock import AsyncMock, MagicMock, patch

from lib.collectors.sevenps.storage.postgres import (
    DatabaseConnectionError,
    PostgresDBStorage,
    RecordNotFoundException,
)

PATCH_ROOT = "lib.collectors.sevenps.storage.postgres"


# ───────────────────────────── helpers ───────────────────────────── #

def _make_fake_pool(closed: bool = True):
    """
    Build (fake_pool, fake_cursor) such that the real psycopg semantics are
    reproduced closely:

      • pool.connection()  → *returns* an **async context-manager** (not a coroutine)
      • conn.cursor()      → idem
      • .open/.close/.commit/.execute/.fetchall are awaitables (AsyncMock)
    """
    fake_pool = MagicMock()
    fake_pool.closed = closed
    fake_pool.open = AsyncMock()
    fake_pool.close = AsyncMock()

    # connection CM
    fake_conn = MagicMock()
    fake_conn.commit = AsyncMock()

    conn_cm = MagicMock()
    conn_cm.__aenter__ = AsyncMock(return_value=fake_conn)
    conn_cm.__aexit__ = AsyncMock(return_value=False)
    fake_pool.connection = MagicMock(return_value=conn_cm)

    # cursor CM
    fake_cursor = MagicMock()
    fake_cursor.execute = AsyncMock()
    fake_cursor.fetchall = AsyncMock()

    cur_cm = MagicMock()
    cur_cm.__aenter__ = AsyncMock(return_value=fake_cursor)
    cur_cm.__aexit__ = AsyncMock(return_value=False)
    fake_conn.cursor = MagicMock(return_value=cur_cm)

    return fake_pool, fake_cursor


# ───────────────────────────── tests ────────────────────────────── #

class TestPostgresDBStorage(unittest.TestCase):
    # ------------- constructor paths ------------- #

    @patch(f"{PATCH_ROOT}.AsyncConnectionPool")
    @patch(f"{PATCH_ROOT}.os.getenv", return_value="LOCAL")
    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_init_local_success(self, m_run_tc, _m_env, m_pool_cls):
        fake_pool, _ = _make_fake_pool(closed=True)
        m_pool_cls.return_value = fake_pool

        class DummyFuture:
            def result(self):
                return None

        m_run_tc.return_value = DummyFuture()

        PostgresDBStorage({"min_connections": 1, "max_connections": 2})

        m_pool_cls.assert_called_once()
        self.assertTrue(m_run_tc.called)

    @patch(f"{PATCH_ROOT}.AsyncConnectionPool", side_effect=Exception("boom"))
    @patch(f"{PATCH_ROOT}.os.getenv", return_value="CLOUD")
    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_init_cloud_failure(self, _m_run_tc, _m_env, _m_pool_cls):
        with self.assertRaises(DatabaseConnectionError):
            PostgresDBStorage({})

    # -------- ensure_pool_open_async / _close_pool ---------- #

    def test_pool_open_and_close_coroutines(self):
        fake_pool, _ = _make_fake_pool(closed=True)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool

        ensure_coro = PostgresDBStorage._ensure_pool_open_async.__get__(storage)
        close_coro = PostgresDBStorage._close_pool.__get__(storage)

        loop = asyncio.new_event_loop()
        loop.run_until_complete(ensure_coro())
        loop.close()
        fake_pool.open.assert_awaited_once()

        fake_pool.closed = False
        fake_pool.open.reset_mock()
        loop = asyncio.new_event_loop()
        loop.run_until_complete(ensure_coro())
        loop.close()
        fake_pool.open.assert_not_awaited()

        loop = asyncio.new_event_loop()
        loop.run_until_complete(close_coro())
        loop.close()
        fake_pool.close.assert_awaited_once()

    # ----------------------- _execute ----------------------- #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_execute_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, val):
                self._val = val

            def result(self):
                return self._val

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return DummyFuture(res)

        m_run_tc.side_effect = fake_run

        storage._execute("INSERT INTO xyz(id) VALUES(%s)", {"id": 1})
        fake_cursor.execute.assert_awaited_once_with(
            "INSERT INTO xyz(id) VALUES(%s)", {"id": 1}
        )
        fake_pool.connection.return_value.__aenter__.return_value.commit.assert_awaited_once()

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_execute_failure(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.execute.side_effect = Exception("boom")

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, res_or_exc):
                self._res = res_or_exc

            def result(self):
                if isinstance(self._res, Exception):
                    raise self._res
                return self._res

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            try:
                res = runner.run_until_complete(coro)
                return DummyFuture(res)
            except Exception as e:
                return DummyFuture(e)
            finally:
                runner.close()

        m_run_tc.side_effect = fake_run

        with self.assertRaises(Exception):
            storage._execute("INSERT BAD", None)

    # --------------------- fetch_all ----------------------- #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_fetch_all(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = [(1,), (2,)]

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, val):
                self._val = val

            def result(self):
                return self._val

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return DummyFuture(res)

        m_run_tc.side_effect = fake_run
        rows = storage.fetch_all("SELECT * FROM foo", None)
        self.assertEqual(rows, [(1,), (2,)])

    # -------- store_test_set_data edge + happy paths -------- #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_store_test_set_data_value_error(self, _m_run_tc):
        fake_pool, _ = _make_fake_pool(closed=False)
        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()
        with self.assertRaises(ValueError):
            storage.store_test_set_data([])

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_store_test_set_data_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, val):
                self._val = val

            def result(self):
                return self._val

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return DummyFuture(res)

        m_run_tc.side_effect = fake_run

        record = {k: "x" for k in (
            "repo_url", "artifact_url", "artifact_name", "artifact_version",
            "test_set_type", "test_request_id", "component_asv", "component_bap",
            "report_doc", "report_source", "traceability_doc",
            "github_org", "github_repo", "github_branch",
            "pr_url", "pr_id_branch", "pr_source_branch",
            "build_id", "test_type_details", "test_run_status"
        )}
        storage.store_test_set_data([record])
        self.assertTrue(fake_cursor.execute.await_count >= 1)

    # ---------------------- get_test_set_data --------------------- #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_get_test_set_data_artifact_success(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = [("json-1",), ("json-2",)]

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, val):
                self._val = val

            def result(self):
                return self._val

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return DummyFuture(res)

        m_run_tc.side_effect = fake_run
        out = storage.get_test_set_data(artifact_id="A-1")
        self.assertEqual(out, ["json-1", "json-2"])

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_get_test_set_data_not_found(self, m_run_tc):
        fake_pool, fake_cursor = _make_fake_pool(closed=False)
        fake_cursor.fetchall.return_value = []

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()

        class DummyFuture:
            def __init__(self, res_or_exc):
                self._res = res_or_exc

            def result(self):
                if isinstance(self._res, Exception):
                    raise self._res
                return self._res

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            try:
                res = runner.run_until_complete(coro)
                return DummyFuture(res)
            except Exception as e:
                return DummyFuture(e)
            finally:
                runner.close()

        m_run_tc.side_effect = fake_run
        with self.assertRaises(RecordNotFoundException):
            storage.get_test_set_data(test_request_id="T-1")

    # -------------------------- close() -------------------------- #

    @patch(f"{PATCH_ROOT}.asyncio.run_coroutine_threadsafe")
    def test_close(self, m_run_tc):
        fake_pool, _ = _make_fake_pool(closed=False)

        storage = PostgresDBStorage.__new__(PostgresDBStorage)
        storage._pool = fake_pool
        storage._loop = asyncio.new_event_loop()
        storage._thread = MagicMock()

        class DummyFuture:
            def __init__(self, val):
                self._val = val

            def result(self):
                return self._val

        def fake_run(coro, loop):
            runner = asyncio.new_event_loop()
            res = runner.run_until_complete(coro)
            runner.close()
            return DummyFuture(res)

        m_run_tc.side_effect = fake_run
        storage.close()

        fake_pool.close.assert_awaited_once()
        storage._thread.join.assert_called()


if __name__ == "__main__":
    unittest.main()
